Machine learning is behind chatbots and predictive text, language translation apps, the shows Netflix suggests to you, and how your social media feeds are presented. It powers autonomous vehicles and machines that can diagnose medical conditions based on images. When companies today deploy artificial intelligence programs, they are most likely using machine learning — so much so that the terms are often used interchangeably, and sometimes ambiguously. Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed. “In just the last five or 10 years, machine learning has become a critical way, arguably the most important way, most parts of AI are done,” said MIT Sloan professorThomas W. Malone, the founding director of the MIT Center for Collective Intelligence. “So that's why some people use the terms AI and machine learning almost as synonymous … most of the current advances in AI have involved machine learning.” With the growing ubiquity of machine learning, everyone in business is likely to encounter it and will need some working knowledge about this field. A 2020 Deloitte survey found that 67% of companies are using machine learning, and 97% are using or planning to use it in the next year. From manufacturing to retail and banking to bakeries, even legacy companies are using machine learning to unlock new value or boost efficiency. “Machine learning is changing, or will change, every industry, and leaders need to understand the basic principles, the potential, and the limitations,” said MIT computer science professor Aleksander Madry, director of the MIT Center for Deployable Machine Learning. While not everyone needs to know the technical details, they should understand what the technology does and what it can and cannot do, Madry added. “I don’t think anyone can afford not to be aware of what’s happening.” That includes being aware of the social, societal, and ethical implications of machine learning. “It's important to engage and begin to understand these tools, and then think about how you're going to use them well. We have to use these [tools] for the good of everybody,” said Dr. Joan LaRovere, MBA ’16, a pediatric cardiac intensive care physician and co-founder of the nonprofit The Virtue Foundation. “AI has so much potential to do good, and we need to really keep that in our lenses as we're thinking about this. How do we use this to do good and better the world?” Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior. Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems. The goal of AI is to create computer models that exhibit “intelligent behaviors” like humans, according to Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL. This means machines that can recognize a visual scene, understand a text written in natural language, or perform an action in the physical world. Machine learning is one way to use AI. It was defined in the 1950s by AI pioneer Arthur Samuel as “the field of study that gives computers the ability to learn without explicitly being programmed.” The definition holds true, according toMikey Shulman, a lecturer at MIT Sloan and head of machine learning at Kensho, which specializes in artificial intelligence for the finance and U.S. intelligence communities. He compared the traditional way of programming computers, or “software 1.0,” to baking, where a recipe calls for precise amounts of ingredients and tells the baker to mix for an exact amount of time. Traditional programming similarly requires creating detailed instructions for the computer to follow. But in some cases, writing a program for the machine to follow is time-consuming or impossible, such as training a computer to recognize pictures of different people. While humans can do this task easily, it’s difficult to tell a computer how to do it. Machine learning takes the approach of letting computers learn to program themselves through experience. Machine learning starts with data — numbers, photos, or text, like bank transactions, pictures of people or even bakery items, repair records, time series data from sensors, or sales reports. The data is gathered and prepared to be used as training data, or the information the machine learning model will be trained on. The more data, the better the program. From there, programmers choose a machine learning model to use, supply the data, and let the computer model train itself to find patterns or make predictions. Over time the human programmer can also tweak the model, including changing its parameters, to help push it toward more accurate results. (Research scientist Janelle Shane’s website AI Weirdness is an entertaining look at how machine learning algorithms learn and how they can get things wrong — as happened when an algorithm tried to generate recipes and created Chocolate Chicken Chicken Cake.) Some data is held out from the training data to be used as evaluation data, which tests how accurate the machine learning model is when it is shown new data. The result is a model that can be used in the future with different sets of data. Successful machine learning algorithms can do different things, Malone wrote in a recent research brief about AI and the future of work that was co-authored by MIT professor and CSAIL director Daniela Rus and Robert Laubacher, the associate director of the MIT Center for Collective Intelligence. “The function of a machine learning system can be descriptive, meaning that the system uses the data to explain what happened; predictive, meaning the system uses the data to predict what will happen; or prescriptive, meaning the system will use the data to make suggestions about what action to take,” the researchers wrote. There are three subcategories of machine learning: Supervised machine learning models are trained with labeled data sets, which allow the models to learn and grow more accurate over time. For example, an algorithm would be trained with pictures of dogs and other things, all labeled by humans, and the machine would learn ways to identify pictures of dogs on its own. Supervised machine learning is the most common type used today. In unsupervised machine learning, a program looks for patterns in unlabeled data. Unsupervised machine learning can find patterns or trends that people aren’t explicitly looking for. For example, an unsupervised machine learning program could look through online sales data and identify different types of clients making purchases. Reinforcement machine learning trains machines through trial and error to take the best action by establishing a reward system. Reinforcement learning can train models to play games or train autonomous vehicles to drive by telling the machine when it made the right decisions, which helps it learn over time what actions it should take. Source: Thomas Malone | MIT Sloan. See: https://bit.ly/3gvRho2, Figure 2.  In the Work of the Future brief, Malone noted that machine learning is best suited for situations with lots of data — thousands or millions of examples, like recordings from previous conversations with customers, sensor logs from machines, or ATM transactions. For example, Google Translate was possible because it “trained” on the vast amount of information on the web, in different languages. In some cases, machine learning can gain insight or automate decision-making in cases where humans would not be able to, Madry said. “It may not only be more efficient and less costly to have an algorithm do this, but sometimes humans just literally are not able to do it,” he said. Google search is an example of something that humans can do, but never at the scale and speed at which the Google models are able to show potential answers every time a person types in a query, Malone said. “That’s not an example of computers putting people out of work. It's an example of computers doing things that would not have been remotely economically feasible if they had to be done by humans.” Machine learning is also associated with several other artificial intelligence subfields: Natural language processing Natural language processing is a field of machine learning in which machines learn to understand natural language as spoken and written by humans, instead of the data and numbers normally used to program computers. This allows machines to recognize language, understand it, and respond to it, as well as create new text and translate between languages. Natural language processing enables familiar technology like chatbots and digital assistants like Siri or Alexa. Neural networks Neural networks are a commonly used, specific class of machine learning algorithms. Artificial neural networks are modeled on the human brain, in which thousands or millions of processing nodes are interconnected and organized into layers. In an artificial neural network, cells, or nodes, are connected, with each cell processing inputs and producing an output that is sent to other neurons. Labeled data moves through the nodes, or cells, with each cell performing a different function. In a neural network trained to identify whether a picture contains a cat or not, the different nodes would assess the information and arrive at an output that indicates whether a picture features a cat. Deep learning Deep learning networks are neural networks with many layers. The layered network can process extensive amounts of data and determine the “weight” of each link in the network — for example, in an image recognition system, some layers of the neural network might detect individual features of a face, like eyes, nose, or mouth, while another layer would be able to tell whether those features appear in a way that indicates a face. Like neural networks, deep learning is modeled on the way the human brain works and powers many machine learning uses, like autonomous vehicles, chatbots, and medical diagnostics. “The more layers you have, the more potential you have for doing complex things well,” Malone said. Deep learning requires a great deal of computing power, which raises concerns about its economic and environmental sustainability. Machine learning is the core of some companies’ business models, like in the case of Netflix’s suggestions algorithm or Google’s search engine. Other companies are engaging deeply with machine learning, though it’s not their main business proposition. 67% of companies are using machine learning, according to a recent survey. Others are still trying to determine how to use machine learning in a beneficial way. “In my opinion, one of the hardest problems in machine learning is figuring out what problems I can solve with machine learning,” Shulman said. “There’s still a gap in the understanding.” In a 2018 paper, researchers from the MIT Initiative on the Digital Economy outlined a 21-question rubric to determine whether a task is suitable for machine learning. The researchers found that no occupation will be untouched by machine learning, but no occupation is likely to be completely taken over by it. The way to unleash machine learning success, the researchers found, was to reorganize jobs into discrete tasks, some which can be done by machine learning, and others that require a human. Companies are already using machine learning in several ways, including: Recommendation algorithms. The recommendation engines behind Netflix and YouTube suggestions, what information appears on your Facebook feed, and product recommendations are fueled by machine learning. “[The algorithms] are trying to learn our preferences,” Madry said. “They want to learn, like on Twitter, what tweets we want them to show us, on Facebook, what ads to display, what posts or liked content to share with us.” Image analysis and object detection. Machine learning can analyze images for different information, like learning to identify people and tell them apart — though facial recognition algorithms are controversial. Business uses for this vary. Shulman noted that hedge funds famously use machine learning to analyze the number of cars in parking lots, which helps them learn how companies are performing and make good bets. Fraud detection. Machines can analyze patterns, like how someone normally spends or where they normally shop, to identify potentially fraudulent credit card transactions, log-in attempts, or spam emails. Automatic helplines or chatbots. Many companies are deploying online chatbots, in which customers or clients don’t speak to humans, but instead interact with a machine. These algorithms use machine learning and natural language processing, with the bots learning from records of past conversations to come up with appropriate responses. Self-driving cars. Much of the technology behind self-driving cars is based on machine learning, deep learning in particular. Medical imaging and diagnostics. Machine learning programs can be trained to examine medical images or other information and look for certain markers of illness, like a tool that can predict cancer risk based on a mammogram. Read report: Artificial Intelligence and the Future of Work While machine learning is fueling technology that can help workers or open new possibilities for businesses, there are several things business leaders should know about machine learning and its limits. Explainability One area of concern is what some experts call explainability, or the ability to be clear about what the machine learning models are doing and how they make decisions. “Understanding why a model does what it does is actually a very difficult question, and you always have to ask yourself that,” Madry said. “You should never treat this as a black box, that just comes as an oracle … yes, you should use it, but then try to get a feeling of what are the rules of thumb that it came up with? And then validate them.” This is especially important because systems can be fooled and undermined, or just fail on certain tasks, even those humans can perform easily. For example, adjusting the metadata in images can confuse computers — with a few adjustments, a machine identifies a picture of a dog as an ostrich. Madry pointed out another example in which a machine learning algorithm examining X-rays seemed to outperform physicians. But it turned out the algorithm was correlating results with the machines that took the image, not necessarily the image itself. Tuberculosis is more common in developing countries, which tend to have older machines. The machine learning program learned that if the X-ray was taken on an older machine, the patient was more likely to have tuberculosis. It completed the task, but not in the way the programmers intended or would find useful. The importance of explaining how a model is working — and its accuracy — can vary depending on how it’s being used, Shulman said. While most well-posed problems can be solved through machine learning, he said, people should assume right now that the models only perform to about 95% of human accuracy. It might be okay with the programmer and the viewer if an algorithm recommending movies is 95% accurate, but that level of accuracy wouldn’t be enough for a self-driving vehicle or a program designed to find serious flaws in machinery. Bias and unintended outcomes Machines are trained by humans, and human biases can be incorporated into algorithms — if biased information, or data that reflects existing inequities, is fed to a machine learning program, the program will learn to replicate it and perpetuate forms of discrimination. Chatbots trained on how people converse on Twitter can pick up on offensive and racist language, for example. In some cases, machine learning models create or exacerbate social problems. For example, Facebook has used machine learning as a tool to show users ads and content that will interest and engage them — which has led to models showing people extreme content that leads to polarization and the spread of conspiracy theories when people are shown incendiary, partisan, or inaccurate content. Ways to fight against bias in machine learning including carefully vetting training data and putting organizational support behind ethical artificial intelligence efforts, like making sure your organization embraces human-centered AI, the practice of seeking input from people of different backgrounds, experiences, and lifestyles when designing AI systems. Initiatives working on this issue include the Algorithmic Justice League and The Moral Machine project. Shulman said executives tend to struggle with understanding where machine learning can actually add value to their company. What’s gimmicky for one company is core to another, and businesses should avoid trends and find business use cases that work for them. The way machine learning works for Amazon is probably not going to translate at a car company, Shulman said — while Amazon has found success with voice assistants and voice-operated speakers, that doesn’t mean car companies should prioritize adding speakers to cars. More likely, he said, the car company might find a way to use machine learning on the factory line that saves or makes a great deal of money. “The field is moving so quickly, and that's awesome, but it makes it hard for executives to make decisions about it and to decide how much resourcing to pour into it,” Shulman said. It’s also best to avoid looking at machine learning as a solution in search of a problem, Shulman said. Some companies might end up trying to backport machine learning into a business use. Instead of starting with a focus on technology, businesses should start with a focus on a business problem or customer need that could be met with machine learning. A basic understanding of machine learning is important, LaRovere said, but finding the right machine learning use ultimately rests on people with different expertise working together. “I'm not a data scientist. I'm not doing the actual data engineering work — all the data acquisition, processing, and wrangling to enable machine learning applications — but I understand it well enough to be able to work with those teams to get the answers we need and have the impact we need,” she said. “You really have to work in a team.” Sign-up for a Machine Learning in Business Course. Watch an Introduction to Machine Learning through MIT OpenCourseWare. Read about how an AI pioneer thinks companies can use machine learning to transform. Watch a discussion with two AI experts about machine learning strides and limitations. Take a look at the seven steps of machine learning. Read next: 7 lessons for successful machine learning projects While machine learning and deep learning models often produce good classifications and predictions, they are almost never perfect. Models almost always have some percentage of false positive and false negative predictions. That’s sometimes acceptable, but matters a lot when the stakes are high. For example, a drone weapons system that falsely identifies a school as a terrorist base could inadvertently kill innocent children and teachers unless a human operator overrides the decision to attack. The operator needs to know why the AI classified the school as a target and the uncertainties of the decision before allowing or overriding the attack. There have certainly been cases where terrorists used schools, hospitals, and religious centers as bases for missile attacks. Was this school one of those? Is there intelligence or a recent observation that identifies the school as currently occupied by such terrorists? Are there reports or observations that establish that no students or teachers are present in the school? If there are no such explanations, the model is essentially a black box, and that’s a huge problem. For any AI decision that has an impact — not only a life and death impact, but also a financial impact or a regulatory impact — it is important to be able to clarify what factors went into the model’s decision. Explainable AI (XAI), also called interpretable AI, refers to machine learning and deep learning methods that can explain their decisions in a way that humans can understand. The hope is that XAI will eventually become just as accurate as black-box models. Explainability can be ante-hoc (directly interpretable white-box models) or post-hoc (techniques to explain a previously trained model or its prediction). Ante-hoc models include explainable neural networks (xNNs), explainable boosting machines (EBMs), supersparse linear integer models (SLIMs), reversed time attention model (RETAIN), and Bayesian deep learning (BDL). Post-hoc explainability methods include local interpretable model-agnostic explanations (LIME) as well as local and global visualizations of model predictions such as accumulated local effect (ALE) plots, one-dimensional and two-dimensional partial dependence plots (PDPs), individual conditional expectation (ICE) plots, and decision tree surrogate models. If you followed all the links above and read the papers, more power to you – and feel free to skip this section. The write-ups below are short summaries. The first five are ante-hoc models, and the rest are post-hoc methods. Explainable neural networks (xNNs) are based on additive index models, which can approximate complex functions. The elements of these models are called projection indexes and ridge functions. The xNNs are neural networks designed to learn additive index models, with subnetworks that learn the ridge functions. The first hidden layer uses linear activation functions, while the subnetworks typically consist of multiple fully-connected layers and use nonlinear activation functions. xNNs can be used by themselves as explainable predictive models built directly from data. They can also be used as surrogate models to explain other nonparametric models, such as tree-based methods and feedforward neural networks. The 2018 paper on xNNs comes from Wells Fargo. As I mentioned when I reviewed Azure AI and Machine Learning, Microsoft has released the InterpretML package as open source and has incorporated it into an Explanation dashboard in Azure Machine Learning. Among its many features, InterpretML has a “glassbox” model from Microsoft Research called the explainable boosting machine (EBM). EBM was designed to be as accurate as random forest and boosted trees while also being easy to interpret. It’s a generalized additive model, with some refinements. EBM learns each feature function using modern machine learning techniques such as bagging and gradient boosting. The boosting procedure is restricted to train on one feature at a time in round-robin fashion using a very low learning rate so that feature order does not matter. It can also detect and include pairwise interaction terms. The implementation, in C++ and Python, is parallelizable. Supersparse linear integer model (SLIM) is an integer programming problem that optimizes direct measures of accuracy (the 0-1 loss) and sparsity (the l0-seminorm) while restricting coefficients to a small set of coprime integers. SLIM can create data-driven scoring systems, which are useful in medical screening. The reverse time attention (RETAIN) model is an interpretable predictive model for electronic health records (EHR) data. RETAIN achieves high accuracy while remaining clinically interpretable. It’s based on a two-level neural attention model that detects influential past visits and significant clinical variables within those visits (e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR data in a reverse time order so that recent clinical visits are likely to receive higher attention. The test data discussed in the RETAIN paper predicted heart failure based on diagnoses and medications over time. Bayesian deep learning (BDL) offers principled uncertainty estimates from deep learning architectures. Basically, BDL helps to remedy the issue that most deep learning models can’t model their uncertainty by modeling an ensemble of networks with weights drawn from a learned probability distribution. BDL typically only doubles the number of parameters. Local interpretable model-agnostic explanations (LIME) is a post-hoc technique to explain the predictions of any machine learning classifier by perturbing the features of an input and examining the predictions. The key intuition behind LIME is that it is much easier to approximate a black-box model by a simple model locally (in the neighborhood of the prediction we want to explain), as opposed to trying to approximate a model globally. It applies both to the text and image domains. The LIME Python package is on PyPI with source on GitHub. It’s also included in InterpretML. ALE plots for bicycle rentals. From Interpretable Machine Learning by Christoph Molnar. Accumulated local effects (ALE) describe how features influence the prediction of a machine learning model on average, using the differences caused by local perturbations within intervals. ALE plots are a faster and unbiased alternative to partial dependence plots (PDPs). PDPs have a serious problem when the features are correlated. ALE plots are available in R and in Python. PDP plots for bicycle rentals. From Interpretable Machine Learning by Christoph Molnar. A partial dependence plot (PDP or PD plot) shows the marginal effect one or two features have on the predicted outcome of a machine learning model, using an average over the dataset. It’s easier to understand PDPs than ALEs, although ALEs are often preferable in practice. The PDP and ALE for a given feature often look similar. PDP plots in R are available in the iml, pdp, and DALEX packages; in Python, they are included in Scikit-learn and PDPbox. ICE plots for bicycle rentals. From Interpretable Machine Learning by Christoph Molnar. CC Individual conditional expectation (ICE) plots display one line per instance that shows how the instance’s prediction changes when a feature changes. Essentially, a PDP is the average of the lines of an ICE plot. Individual conditional expectation curves are even more intuitive to understand than partial dependence plots. ICE plots in R are available in the iml, ICEbox, and pdp packages; in Python, they are available in Scikit-learn. A global surrogate model is an interpretable model that is trained to approximate the predictions of a black box model. Linear models and decision tree models are common choices for global surrogates. To create a surrogate model, you basically train it against dataset features and the black box model predictions. You can evaluate the surrogate against the black box model by looking at the R-squared between them. If the surrogate is acceptable, then you can use it for interpretation. DARPA, the Defense Advanced Research Projects Agency, has an active program on explainable artificial intelligence managed by Dr. Matt Turek. From the program’s website (emphasis mine): The Explainable AI (XAI) program aims to create a suite of machine learning techniques that: New machine-learning systems will have the ability to explain their rationale, characterize their strengths and weaknesses, and convey an understanding of how they will behave in the future. The strategy for achieving that goal is to develop new or modified machine-learning techniques that will produce more explainable models. These models will be combined with state-of-the-art human-computer interface techniques capable of translating models into understandable and useful explanation dialogues for the end user. Our strategy is to pursue a variety of techniques in order to generate a portfolio of methods that will provide future developers with a range of design options covering the performance-versus-explainability trade space. The Google Cloud Platform offers Explainable AI tools and frameworks that work with its AutoML Tables and AI Platform services. These tools help you to understand feature attributions and visually investigate model behavior using the What-If Tool. Feature attribution overlays from a Google image classification model. AI Explanations give you a score that explains how each factor contributed to the final result of the model predictions. The What-If Tool lets you investigate model performances for a range of features in your dataset, optimization strategies, and even manipulations to individual datapoint values. Continuous evaluation lets you sample the prediction from trained machine learning models deployed to AI Platform and provide ground truth labels for prediction inputs using the continuous evaluation capability. The Data Labeling Service compares model predictions with ground truth labels to help you improve model performance. Whenever you request a prediction on AI Platform, AI Explanations tells you how much each feature in the data contributed to the predicted result. H2O Driverless AI does explainable AI with its machine learning interpretability (MLI) module. This capability in H2O Driverless AI employs a combination of techniques and methodologies such as LIME, Shapley, surrogate decision trees, and partial dependence in an interactive dashboard to explain the results of both Driverless AI models and external models. In addition, the auto documentation (AutoDoc) capability of Driverless AI provides transparency and an audit trail for Driverless AI models by generating a single document with all relevant data analysis, modeling, and explanatory results. This document helps data scientists save time in documenting the model, and it can be given to a business person or even model validators to increase understanding and trust in Driverless AI models. DataRobot, which I reviewed in December 2020, includes several components that result in highly human-interpretable models: DataRobot works to ensure that models are highly interpretable, minimizing model risk and making it easy for any enterprise to comply with regulations and best practices. Dataiku provides a collection of various interpretability techniques to better understand and explain machine learning model behavior, including: Explainable AI is finally starting to receive the attention it deserves. We aren’t quite at the point where “glassbox” models are always preferred over black box models, but we’re getting close. To fill the gap, we have a variety of post-hoc techniques for explaining black box models. In general terms, AI refers to a broad field of science encompassing not only computer science but also psychology, philosophy, linguistics and other areas. AI is concerned with getting computers to do tasks that would normally require human intelligence. Having said that, there are many points of view on AI and many definitions exist. Below, some definitions highlight its key characteristics.
Some general definitions

“Artificial intelligence is a computerised system that exhibits behaviour that is commonly thought of as requiring intelligence.” (1)
“Artificial Intelligence is the science of making machines do things that would require intelligence if done by man.” (2)

The founding father of AI, Alan Turing, defines this discipline as:

“AI is the science and engineering of making intelligent machines, especially intelligent computer programs.” (3)

In these definitions, the concept of intelligence refers to some kind of ability to plan, reason and learn, sense and build some kind of perception of knowledge and communicate in natural language. In general terms, AI refers to a broad field of science encompassing not only computer science but also psychology, philosophy, linguistics and other areas. AI is concerned with getting computers to do tasks that would normally require human intelligence. Having said that, there are many points of view on AI and many definitions exist. Below, some definitions highlight its key characteristics. The founding father of AI, Alan Turing, defines this discipline as: In these definitions, the concept of intelligence refers to some kind of ability to plan, reason and learn, sense and build some kind of perception of knowledge and communicate in natural language.  A chess computer could beat a human in playing chess, but that same computer program couldn’t solve a complex math problem. Virtually all current AI is narrow, meaning it can only do what it is designed to do. This means that for every problem, a specific algorithm needs to be designed to solve it. Narrow AIs are mostly much better than humans at the task they were made for: for example look at face recognition, chess computers, calculus, translation. The holy grail of AI is a General AI, a single system that can learn and then solve any problem it is presented. This is exactly what humans do: we can specialise in a specific topic, from abstract maths to psychology and from sports to art. We can become experts at all of them.
An AI system combines and utilises mainly machine learning and other types of data analytics methods to achieve artificial intelligence capabilities. A chess computer could beat a human in playing chess, but that same computer program couldn’t solve a complex math problem. Virtually all current AI is narrow, meaning it can only do what it is designed to do. This means that for every problem, a specific algorithm needs to be designed to solve it. Narrow AIs are mostly much better than humans at the task they were made for: for example look at face recognition, chess computers, calculus, translation. The holy grail of AI is a General AI, a single system that can learn and then solve any problem it is presented. This is exactly what humans do: we can specialise in a specific topic, from abstract maths to psychology and from sports to art. We can become experts at all of them. An AI system combines and utilises mainly machine learning and other types of data analytics methods to achieve artificial intelligence capabilities.  Machine learning is the process in which a computer distills regularities from training data (4). If for example you want to write an algorithm to identify spam in e-mails, you will have to train the algorithm by exposing it to many examples of e-mails that are manually tagged as being spam or not-spam. The algorithm “learns” to identify patterns, like occurrence of certain words or combinations of words, that determine the chance of an e-mail being spam.
Machine learning can be applied to many different problems and data sets. You can train an algorithm to identify pictures of cats in photo collections, potential fraud cases in insurance claims, to transform handwriting into structured text, speech into text, etcetera. All these examples would require tagged training sets. Depending on the technique used, an algorithm can improve itself by adding a feedback loop that tells it in which cases it made mistakes.
The difference with AI however is that a machine-learning algorithm will never understand what it was trained to do. It may be able to identify spam, but it will not know what spam is or understand why we want it to be identified. And if there is a new sort of spam emerging, it will probably not be able to identify it unless someone (human) re-trains the algorithm.
Machine learning forms the basis of most AI systems. But while a machine-learning system may look intelligent', in our definition of AI, it in fact isn't. Machine learning is the process in which a computer distills regularities from training data (4). If for example you want to write an algorithm to identify spam in e-mails, you will have to train the algorithm by exposing it to many examples of e-mails that are manually tagged as being spam or not-spam. The algorithm “learns” to identify patterns, like occurrence of certain words or combinations of words, that determine the chance of an e-mail being spam. Machine learning can be applied to many different problems and data sets. You can train an algorithm to identify pictures of cats in photo collections, potential fraud cases in insurance claims, to transform handwriting into structured text, speech into text, etcetera. All these examples would require tagged training sets. Depending on the technique used, an algorithm can improve itself by adding a feedback loop that tells it in which cases it made mistakes. The difference with AI however is that a machine-learning algorithm will never understand what it was trained to do. It may be able to identify spam, but it will not know what spam is or understand why we want it to be identified. And if there is a new sort of spam emerging, it will probably not be able to identify it unless someone (human) re-trains the algorithm. Machine learning forms the basis of most AI systems. But while a machine-learning system may look intelligent', in our definition of AI, it in fact isn't.  Cognitive Analytics is a subfield of AI that deals with cognitive behaviour we associate with 'thinking' as opposed to perception and motor control. Thinking allows an entity to obtain information from observations, to learn and communicate.
A cognitive system is capable of extracting information from unstructured data by extracting concepts and relationships into a knowledge base. For example, from a text about Barack Obama, the relations from the figure below can be extracted using Natural Language Processing. 80 percent of all company data is unstructured and current Cognitive Analytics systems can search all of it to find the answer to your question. Cognitive Analytics is a subfield of AI that deals with cognitive behaviour we associate with 'thinking' as opposed to perception and motor control. Thinking allows an entity to obtain information from observations, to learn and communicate. A cognitive system is capable of extracting information from unstructured data by extracting concepts and relationships into a knowledge base. For example, from a text about Barack Obama, the relations from the figure below can be extracted using Natural Language Processing. 80 percent of all company data is unstructured and current Cognitive Analytics systems can search all of it to find the answer to your question.  The Cognitive System improves its performance over time in two major ways. Firstly, through interaction with humans, and using feedback from the conversation partner or by observing two interacting humans. Secondly, from all the data in the knowledge base, new knowledge can be obtained using inference.
Another important aspect of Cognitive Analytics is the ability to use context. Context enables a Cognitive Analytics system to infer meaning from language. For example, a chatbot can take into account the conversation history to infer who is referred to by the word he:
User: Who is Obama’s wife?
AI: Michelle Obama.
User: How old is he?
AI: Barack Obama is 55 years old.
For this simple exercise, the system needs to be aware of names that represent people, relationships between people, gender and the common sense to infer that Obama refers to Barack Obama. All of this contextual information is required to make the right inferences to answer both questions.
Since Cognitive Systems can use contextual information, can understand unstructured data and reason about information, they can communicate with humans as well. This enables the system to respond to a question posed in English, no longer requiring the time-consuming process of converting the question into a format the computer can work with. For example, a call center representative cognitive system can quickly answer a customer’s question about camping gear by using information from product descriptions, customer reviews, sales histories, topical blogs, and travel magazines (5).
Cognitive Systems can communicate through many media, including speech, image, video, sign language, graphs or any combination of these. The Cognitive System improves its performance over time in two major ways. Firstly, through interaction with humans, and using feedback from the conversation partner or by observing two interacting humans. Secondly, from all the data in the knowledge base, new knowledge can be obtained using inference. Another important aspect of Cognitive Analytics is the ability to use context. Context enables a Cognitive Analytics system to infer meaning from language. For example, a chatbot can take into account the conversation history to infer who is referred to by the word he: User: Who is Obama’s wife?
AI: Michelle Obama.
User: How old is he?
AI: Barack Obama is 55 years old. For this simple exercise, the system needs to be aware of names that represent people, relationships between people, gender and the common sense to infer that Obama refers to Barack Obama. All of this contextual information is required to make the right inferences to answer both questions. Since Cognitive Systems can use contextual information, can understand unstructured data and reason about information, they can communicate with humans as well. This enables the system to respond to a question posed in English, no longer requiring the time-consuming process of converting the question into a format the computer can work with. For example, a call center representative cognitive system can quickly answer a customer’s question about camping gear by using information from product descriptions, customer reviews, sales histories, topical blogs, and travel magazines (5). Cognitive Systems can communicate through many media, including speech, image, video, sign language, graphs or any combination of these.  AI is an important enabling factor in the design and operationalisation of smart robots and other process-automation applications. In its simplest form, a robot may be a machine that is programmed to perform a simple task by following step-by-step instructions. It could consist of a rule-based engine that explicitly tells the system what to do when a certain condition occurs. A robot in a car factory is programmed like that and hardly considered intelligent.
But robotics exist in a variety of much more intelligent shapes, ranging from unmanned autonomous vehicles (UAV’s), drones, smart vacuum cleaners to intelligent chatbots and smart assistants etc. How advanced robots are is vivid if we look at robots developed by Boston Dynamics (6) and MIT’s Cheetah II (7). Another example is Amelia (8), an intelligent assistant with NLP capabilities. Key aspect of robotics is that it combines hardware (mechanical parts, sensors, screens etc.) with intelligent software and data to perform a task for which certain level of intelligence is required (e.g. orientation, motion, interaction etc.). AI is an important enabling factor in the design and operationalisation of smart robots and other process-automation applications. In its simplest form, a robot may be a machine that is programmed to perform a simple task by following step-by-step instructions. It could consist of a rule-based engine that explicitly tells the system what to do when a certain condition occurs. A robot in a car factory is programmed like that and hardly considered intelligent. But robotics exist in a variety of much more intelligent shapes, ranging from unmanned autonomous vehicles (UAV’s), drones, smart vacuum cleaners to intelligent chatbots and smart assistants etc. How advanced robots are is vivid if we look at robots developed by Boston Dynamics (6) and MIT’s Cheetah II (7). Another example is Amelia (8), an intelligent assistant with NLP capabilities. Key aspect of robotics is that it combines hardware (mechanical parts, sensors, screens etc.) with intelligent software and data to perform a task for which certain level of intelligence is required (e.g. orientation, motion, interaction etc.).  The major theme in underlying the term Smart Machines is autonomy. Smart Machines are systems that –to some extend- are able to make decisions by themselves, requiring no human input. Cognitive Analytics systems as well as robots, or any kind of AI, can be called Smart Machines, as long they adhere to this rule. In the case of a robot, autonomy could consists of a capability to plan where it wants to go, what it wants to achieve and how to overcome obstacles. Rather than being human-controlled or simply following instructions, it could achieve higher-level goals like getting groceries, inspecting buildings and so forth. This is enabled by planning methods, self-preservation instincts on top of the skills that a normal robot already requires.
In the case of a Cognitive System, it will pro-actively try to learn new facts, gauge opinions and learn new common sense rules by engaging in active interaction with humans, asking questions and double-checking them with data found online. It will also actively inform decision makers about changes it has observed. For example, if customer opinions on social media suddenly swing. It could even act upon these changes, taking the example case, it could engage with the customers or share positive opinions on the social media outlets of the company.
Since Smart Machines are autonomous and intelligent, they might start communicating with each other. This leads to multi-agent systems that can make trades to improve their utility. The building-inspecting robot could ask a drone to inspect the roof for it, trading this favour for another favour, like transporting goods or simply currency.
A Cognitive System that becomes a Smart Machine can specialise in a specific area, becoming an expert in that area. Now, other Smart Machines can ask it for information in that area, and it will be able to provide more relevant answers more quickly than a general Cognitive System that is not specialised. Information brokers like this improve the overall utility of the whole network of Smart Machines. The major theme in underlying the term Smart Machines is autonomy. Smart Machines are systems that –to some extend- are able to make decisions by themselves, requiring no human input. Cognitive Analytics systems as well as robots, or any kind of AI, can be called Smart Machines, as long they adhere to this rule. In the case of a robot, autonomy could consists of a capability to plan where it wants to go, what it wants to achieve and how to overcome obstacles. Rather than being human-controlled or simply following instructions, it could achieve higher-level goals like getting groceries, inspecting buildings and so forth. This is enabled by planning methods, self-preservation instincts on top of the skills that a normal robot already requires. In the case of a Cognitive System, it will pro-actively try to learn new facts, gauge opinions and learn new common sense rules by engaging in active interaction with humans, asking questions and double-checking them with data found online. It will also actively inform decision makers about changes it has observed. For example, if customer opinions on social media suddenly swing. It could even act upon these changes, taking the example case, it could engage with the customers or share positive opinions on the social media outlets of the company. Since Smart Machines are autonomous and intelligent, they might start communicating with each other. This leads to multi-agent systems that can make trades to improve their utility. The building-inspecting robot could ask a drone to inspect the roof for it, trading this favour for another favour, like transporting goods or simply currency. A Cognitive System that becomes a Smart Machine can specialise in a specific area, becoming an expert in that area. Now, other Smart Machines can ask it for information in that area, and it will be able to provide more relevant answers more quickly than a general Cognitive System that is not specialised. Information brokers like this improve the overall utility of the whole network of Smart Machines.  The terms Machine Learning, Cognitive Systems, Robotics and smart machines are used often in relationship to AI, or sometimes even as synonyms. AI is a complex field of interest, with many shapes and forms. The terms Machine Learning, Cognitive Systems, Robotics and smart machines are used often in relationship to AI, or sometimes even as synonyms. AI is a complex field of interest, with many shapes and forms.  Part 2: Artificial Intelligence Techniques Explained
Part 3: Applications of Artificial Intelligence 
Part 4: Five technology trends that leap-frog Artificial Intelligence  (1) Preparing for the Future of Artificial Intelligence, NSTC, 2016
(2) 6. Raphael, B. 1976. The thinking computer. San Francisco, CA: W.H. Freeman
(3) http://www-formal.stanford.edu/jmc/whatisai/node1.html
(4) Stephen Lucci, 2016, Artificial intelligence in the 21st century : a living introduction
(5) Deloitte, Cognitive analytics™ The three-minute guide
(6) http://www.bostondynamics.com/
(7) https://biomimetics.mit.edu/research/dynamic-locomotion-mit-cheetah-2
(8) http://www.ipsoft.com/amelia/ (1) Preparing for the Future of Artificial Intelligence, NSTC, 2016
(2) 6. Raphael, B. 1976. The thinking computer. San Francisco, CA: W.H. Freeman
(3) http://www-formal.stanford.edu/jmc/whatisai/node1.html
(4) Stephen Lucci, 2016, Artificial intelligence in the 21st century : a living introduction
(5) Deloitte, Cognitive analytics™ The three-minute guide
(6) http://www.bostondynamics.com/
(7) https://biomimetics.mit.edu/research/dynamic-locomotion-mit-cheetah-2
(8) http://www.ipsoft.com/amelia/ 